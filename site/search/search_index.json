{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Practicals for the 2025 Genome Bioinformatics module","text":""},{"location":"#introduction","title":"Introduction","text":"<p>Cheap sequencing has created the opportunity to perform molecular-genetic analyses on just about anything. Conceptually, doing this would be similar to working with traditional genetic model organisms. But a large difference exists: For traditional genetic model organisms, large teams and communities of expert assemblers, predictors, and curators have put years of efforts into the prerequisites for most genomic analyses, including a reference genome and a set of gene predictions. In contrast, those of us working on \"emerging\" model organisms often have limited or no pre-existing resources and are part of much smaller teams. Emerging model organisms includes most crops, animals and plant pest species, many pathogens, and major models for ecology &amp; evolution.</p> <p>At the end of this module, you should be able to:</p> <ol> <li>inspect and clean short (Illumina) reads,</li> <li>perform genome assembly,</li> <li>assess the quality of the genome assembly using simple statistics,</li> <li>predict protein-coding genes,</li> <li>assess quality of gene predictions,</li> <li>assess quality of the entire process using a biologically meaningful measure.</li> </ol> <p>Info</p> <p>Note: The exemplar datasets are simplified to run on laptops and to fit into the short format of this course. For real projects, much more sophisticated approaches are needed!</p>"},{"location":"#1-prerequisites","title":"1. Prerequisites","text":"<p>Prerequisites for the practicals are:</p> <ul> <li> <p>a basic knowledge of Linux command line. For a refresher, try the SIB's    UNIX fundamentals online course (here). You can also go through a Command Line Bootcamp.</p> </li> <li> <p>a basic knowledge of R programming. The <code>swirl()</code> library course (here)    can help.    In particular, it can be useful:</p> <ul> <li>following the R programming self-led course (skip the sections    Simulation and Dates and Times)</li> <li>following at least the ggplot section of the Exploratory_Data_Analysis    swirl course.</li> </ul> </li> </ul>"},{"location":"#2-practicals","title":"2. Practicals","text":"<ol> <li>Short read cleaning: Illumina   short read cleaning</li> <li>Reads to genome: genome assembly,   quality control</li> <li>Gene prediction: gene prediction,   quality control</li> <li>Population sequencing to genotypes to population genetics statistics:<ol> <li>Mapping reads, calling variants, visualizing variant calls.</li> <li>Analysing variants: PCA, measuring differentiation &amp; diversity.</li> </ol> </li> </ol>"},{"location":"#3-computers","title":"3. Computers","text":"<p>To perform the practicals, you will remotely connect to the Amazon Web Services (AWS) (here, for more informations).</p> <p>You will use an SSH (here for more information), client to connect to a remote shell, where you will run the first three practicals. Some results will be available on a personal web page created for the course. The same web page will allow you to perform the fourth and fifth practicals.</p>"},{"location":"#4-authorscredits","title":"4. Authors/Credits","text":"<p>The initial version of this practical was put together by Yannick Wurm [@yannick], Oksana Riba-Grognuz. It has been revised and improved thanks to efforts of Srishti Arya, Vitaly Voloshin, Matthew Higgins and others. </p>"},{"location":"Apocrita_Access/","title":"Accessing Apocrita","text":"<ul> <li>Apocrita is the high performance computing cluster (HPC) here at QMUL.</li> <li>You will use Apocrita in Week 2 of this module and also for your coursework.</li> <li>Full details on Apocrita can be found here. </li> <li>Before you can use Apocrita you need to request an account and that is the goal for this practical session! </li> </ul>"},{"location":"Apocrita_Access/#what-is-an-ssh-key-pair","title":"What is an SSH-Key Pair?","text":"<p>To connect to Apocrita you will again be using SSH just like how you connected to your Virtual Machines (VMs). However, as Apocrita has a higher level of security you will need to use an SSH-Key Pair. </p> <p>An SSH-Key Pair consists of two cryptographic keys: a public key and a private key.</p> <p>These keys are used to securely authenticate your identity when connecting to remote servers, such as Apocrita.</p> <ul> <li> <p>The public key can be shared freely and is placed on the server you want to access.</p> </li> <li> <p>The private key is kept secure on your own computer and should never be shared.</p> </li> </ul> <p>When you attempt to connect to a server using SSH, the server checks if your public key matches your private key. If they match, you are granted access. This method is more secure than using passwords alone.</p>"},{"location":"Apocrita_Access/#generating-your-ssh-key-pair","title":"Generating your SSH-Key Pair","text":"<p>Now its time to generate your own SSH-Key Pair!</p> <p>Task</p> <p>Task</p> <p>This command will generate two files in your standard SSH directory (<code>~/.ssh/</code>):</p> <ul> <li><code>Apocrita_Key_&lt;YOUR_STUDENT_ID&gt;</code> \u2014 your private key (keep this secure and never share it).</li> <li><code>Apocrita_Key_&lt;YOUR_STUDENT_ID&gt;.pub</code> \u2014 your public key.</li> </ul> <p>Always keep your private key confidential. Only the public key (.pub) should be shared when requested.</p>"},{"location":"Apocrita_Access/#mac-linux-users","title":"Mac &amp; Linux Users","text":"<p>Use the command below to achieve this but please remember to replace <code>&lt;YOUR_QMUL_USERNAME&gt;</code> with your actual QMUL username e.g. <code>bty313</code>:</p> <pre><code># Template\nssh-keygen -t rsa -b 4096 -f ~/.ssh/Apocrita_Key_&lt;YOUR_STUDENT_ID&gt;\n</code></pre> <p>Example, if your QMUL username was bty313</p> <pre><code>ssh-keygen -t rsa -b 4096 -f ~/.ssh/Apocrita_Key_bty313\n</code></pre>"},{"location":"Apocrita_Access/#windows-users","title":"Windows Users","text":"<p>Use the command below in PowerShell to generate your SSH key pair. Remember to replace <code>&lt;YOUR_QMUL_USERNAME&gt;</code> with your actual QMUL username e.g. <code>bty313</code>:</p> <pre><code># Template\nssh-keygen -t rsa -b 4096 -f \"$env:USERPROFILE/.ssh/Apocrita_Key_&lt;YOUR_QMUL_USERNAME&gt;\"\n</code></pre> <p>Example, if your QMUL username was bty313</p> <pre><code>ssh-keygen -t rsa -b 4096 -f \"$env:USERPROFILE/.ssh/Apocrita_Key_bty313\"\n</code></pre> <p>Note: In Windows PowerShell, we use <code>$env:USERPROFILE\\.ssh\\</code> instead of <code>~/.ssh/</code> to specify the path to your SSH directory.</p>"},{"location":"Apocrita_Access/#requesting-an-apocrita-account","title":"Requesting an Apocrita Account","text":"<p>To allow the ITS Research Support Team to create your Apocrita account, please complete the following steps:</p> <ol> <li> <p>Email ITS your public SSH key: </p> <p>Email your public key file <code>Apocrita_Key_&lt;YOUR_STUDENT_ID&gt;.pub</code> to its-research-support@qmul.ac.uk with the subject line \"BIO726P Apocrita Account Request\".</p> <p>In your email message, please include the table below and update the necessary information shown in italics with your own details.</p> Field Value Firstname Your first name Surname Your last name? QMUL username Your QMUL username QMUL email address Your QMUL email address QMUL affiliation msc student Role held at QMUL msc student PI Matthew Higgins Justification BIO726P <p>Attaching your public key: To make it easier to attach your public key to the email, you can copy it from the SSH directory to your Desktop using the appropriate command for your operating system:  </p> <p>For Mac &amp; Linux: <pre><code>cp ~/.ssh/Apocrita_Key_&lt;YOUR_QMUL_USERNAME&gt;.pub ~/Desktop\n</code></pre></p> <p>For Windows (in PowerShell): <pre><code>Copy-Item \"$env:USERPROFILE/.ssh/Apocrita_Key_&lt;YOUR_QMUL_USERNAME&gt;.pub\" \"$env:USERPROFILE/Desktop\"\n</code></pre></p> </li> </ol> <p> Once you have completed this, ITS Research Support will email you within a few days to confirm your account has been created and instructions for how to log into Apocrita.</p> <p></p> <p>If you\u2019d like to learn more about Apocrita before the session with ITS on October 2nd, please check out these resources:</p> <ol> <li>Apocrita Home</li> <li>HPC Introduction</li> <li>Logging Into Apocrita</li> </ol>"},{"location":"admin-notes/","title":"Admin Notes","text":"<p>This is a hidden page that doesn't appear in the navigation but is accessible via URL.</p> <p>You can access this page by going to <code>/admin-notes/</code> in your browser.</p>"},{"location":"admin-notes/#example-content","title":"Example Content","text":"<p>This page could contain: - Internal documentation - Draft content - Admin-only information - Testing content</p> <p>Since this page is not listed in the <code>nav</code> section of <code>mkdocs.yml</code>, it won't appear in the site navigation but will still be built and accessible.</p>"},{"location":"admin-notes/#practical-content","title":"Practical Content","text":"<p>So I have hidden:</p> <ul> <li>http://127.0.0.1:8000/practicals/pt-1-read-cleaning/</li> <li>http://127.0.0.1:8000/practicals/pt-2-assembly/</li> <li>http://127.0.0.1:8000/practicals/pt-2-prediction/</li> </ul>"},{"location":"debugging_process/","title":"The Debugging Process","text":"<p>When working with command-line tools it's common to run into issues / bugs. This guide provides a systematic approach to debugging common errors.</p>"},{"location":"debugging_process/#step-1-switch-on-your-virtual-machine","title":"Step 1. Switch on Your Virtual Machine","text":"<p>If you recieve the following error message: </p> <pre><code>ssh: connect to host matt.genomicscourse.com port 22: Operation timed out\n</code></pre> <p>This indicates your AWS Virtual Machine (VM) is not yet switched on. </p> <p>SOLUTION: To access your AWS Virtual Machine (VM) you have to first have to switch it on via the website switch.genomicscourse.com and wait 2-5 minutes for your machine to boot up! </p>"},{"location":"debugging_process/#step-2-check-you-are-connected-to-your-vm","title":"Step 2. Check you are connected to your VM","text":"<p>When you are connected to your AWS Virtual Machine (VM) there may be times when your connection drops and you are logged out. This can be due to:</p> <ul> <li>Bad internet connection. </li> <li>User inactivity.</li> </ul> <p>How can you tell if you have become disconnected? You may see the following statement printed to your terminal:</p> <pre><code>Connection to matt.genomicscourse.com closed.\nclient_loop: send disconnect: Broken pipe\n</code></pre> <p>Also, it is important to check at the command-prompt (bottom of the terminal, where you type in your commands) your username should be the same as that provided by Vitaly and the host (after the @ symbol) should by an IP address.</p> <pre><code>matt@ip-172-31-38-337:~$ \n</code></pre> <p>SOLUTION: If this happens, make sure to reconnect, via ssh to your AWS VM before continuing with the practical! </p>"},{"location":"debugging_process/#step-3-file-not-found","title":"Step 3. File Not Found","text":"<p>Let's say you are trying to run the command below:</p> <pre><code>fastqc --nogroup --outdir . input/reads.pe1.fastq.gz\n</code></pre> <p>However, you get an error message saying the file cannot be found, doesn't exist, or couldn't be read:</p> <pre><code>Skipping 'input/reads.pe1.fastq.gz' which didn't exist, or couldn't be read\n</code></pre> <p>When a command fails like this, follow these systematic steps to debug the problem:</p> <ul> <li> <p>Check your current directory: Use <code>pwd</code> (print working directory) to confirm where you are in the file system. Ensure you're in the correct location to run the command.</p> </li> <li> <p>Verify the file exists: Use <code>ls -l input/reads.pe1.fastq.gz</code> to check if the file exists at the specified path. If you get a <code>No such file or directory</code> error, the file path is incorrect. Use the <code>tree</code> command to locate where your files actually are.</p> </li> <li> <p>Check the file has content: Use <code>ls -l</code> to check the file size. If the size is 0, the file is empty, indicating a problem with a previous step. You can also use <code>zcat input/reads.pe1.fastq.gz | head</code> to preview the file contents.</p> </li> </ul> <p>SOLUTION: Once you've identified the issue using the steps above, you can:</p> <ul> <li>Navigate to the correct directory using <code>cd</code></li> <li>Correct the file path in your command</li> <li>Check if previous steps in your workflow completed successfully</li> </ul>"},{"location":"ssh/","title":"SSH &amp; Your Virtual Computer!","text":"<p>For each of you we have created your very on AWS instance! This instance you will use to complete the practical work outlined.</p> <p>To switch on your instance please go to https://switch.genomicscourse.com and follow the instructions! Once you computer is switched on proceed with the following sections. </p> <p>You will able to files on you instance using you decidated webpage e.g https://matt.genomicscourse.com/. Please replace matt with your assigned username as follows: https://username.genomicscourse.com/. The webpage will look like the image below: </p> <p></p>"},{"location":"ssh/#ssh-connection","title":"SSH Connection","text":"<p>Please follow the instructions below to connect to your instance via SSH. </p> <p>Click on the link to the operating system you are using</p> <ul> <li> <p>SSH on Linux - For in class practicals you should follow this section.</p> </li> <li> <p>SSH on Mac</p> </li> <li> <p>SSH on Windows</p> </li> </ul>"},{"location":"ssh/#ssh-on-linux","title":"SSH on Linux","text":"<p>Note: Instructions are provided for Ubuntu, but if you are running a  different flavour of linux, the only thing that should be different is how to  open the terminal. From step 3 onwards, everything should be identical.</p> <p>1) On Ubuntu, click on the icon in the top left of the screen</p> <p>2) Type Terminal  and open the terminal application</p> <p></p> <p>3) Into the Linux terminal that appears, type <code>ssh username@servername</code>,     replacing username and servername with the username and server name that you     have been emailed:</p> <pre><code>ssh bt007@bt007.genomicscourse.com\n</code></pre> <p>4) The first time you log in, you will see a message talking about the host's    authenticity, it's fingerprint and asking if you wish to continue.</p> <pre><code>The authenticity of host 'bt007.genomicscourse.com (192.135.232.24)' can't be established.\nECDSA key fingerprint is SHA256:xmvrB9Ke/bXNtpu5PXF6IbUS8wxCtF6SNqZ7VV+IRoU.\nAre you sure you want to continue connecting (yes/no)?\n</code></pre> <p>This message is normal when you log in to a new server. Agreeing will store the server's fingerprint, and the message will not appear again.</p> <p>5) Type <code>yes</code> into the Linux terminal and hit return.</p> <p>6) You will then be asked for a password.</p> <pre><code>bt007@bt007.genomicscourse.com's password:\n</code></pre> <p>Type in the password that you've been emailed, and hit return. Nothing will appear while you type. If you know you have made a mistake, you can hold down backspace, and retype the password.</p> <p>7) Congratulations! You are now logged in!</p>"},{"location":"ssh/#ssh-on-mac","title":"SSH on Mac","text":"<p>1) Press Cmd-Space to open Spotlight, type Terminal, and press enter.</p> <p></p> <p>2) Into the Mac terminal that appears, type <code>ssh username@servername</code>, replacing username and servername with the username and server name that you have been emailed:</p> <pre><code>ssh bt007@bt007.genomicscourse.com\n</code></pre> <p>3) The first time you log in, you will see a message talking about the host's authenticity, it's fingerprint and asksing if you wish to continue.</p> <pre><code>The authenticity of host 'bt007.genomicscourse.com (192.135.232.24)' can't be established.\nECDSA key fingerprint is SHA256:xmvrB9Ke/bXNtpu5PXF6IbUS8wxCtF6SNqZ7VV+IRoU.\nAre you sure you want to continue connecting (yes/no)?\n</code></pre> <p>This message is normal when you log in to a new server. Agreeing will store the server's fingerprint, and the message will not appear again.</p> <p>4) Type <code>yes</code> into the Mac terminal and press enter.</p> <p>5) You will then be asked for a password.</p> <pre><code>bt007@bt007.genomicscourse.com's password:\n</code></pre> <p>Type in the password that you've been emailed, and hit return. Nothing will appear while you type. If you know you have made a mistake, you can hold down backspace, and retype the password.</p> <p>6) Congratulations! You are now logged in!</p>"},{"location":"ssh/#ssh-on-windows","title":"SSH on Windows","text":""},{"location":"ssh/#using-openssh-client-for-windows","title":"Using OpenSSH client for Windows","text":"<p>1) On Windows 10+, type cmd (short for command) into the search box, and press Enter.</p> <p>2) Into the Windows command line that appears, type <code>ssh username@servername</code>,     replacing username and servername with the username and server name that you     have been emailed:</p> <pre><code>ssh bt007@bt007.genomicscourse.com\n</code></pre> <p>If you get a message that there is no command <code>ssh</code>, then you need to enable the OpenSSH client. </p> <p>4) The first time you log in, you will see a message talking about the host's    authenticity, it's fingerprint and asksing if you wish to continue.</p> <pre><code>The authenticity of host 'bt007.genomicscourse.com (192.135.232.24)' can't be established.\nECDSA key fingerprint is SHA256:xmvrB9Ke/bXNtpu5PXF6IbUS8wxCtF6SNqZ7VV+IRoU.\nAre you sure you want to continue connecting (yes/no)?\n</code></pre> <p>This message is normal when you log in to a new server. Agreeing will store the server's fingerprint, and the message will not appear again.</p> <p>5) Type <code>yes</code> into the Windows command line and hit return.</p> <p>6) You will then be asked for a password.</p> <pre><code>bt007@bt007.genomicscourse.com's password:\n</code></pre> <p>Type in the password that you've been emailed, and hit return. Nothing will appear while you type. If you know you have made a mistake, you can hold down backspace, and retype the password.</p> <p>7) Congratulations! You are now logged in!</p>"},{"location":"ssh/#using-mobaxterm-ssh-client","title":"Using MobaXTerm SSH client","text":"<p>If built-in SSH client did not work for you, then use MobaXTerm as exlained below.</p>"},{"location":"ssh/#installing-mobaxterm","title":"Installing MobaXTerm","text":"<p>There are a number of SSH clients you can use, but for the purposes of this practical, we would recommend MobaXTerm.</p> <p>1) Download MobaXTerm from: https://mobaxterm.mobatek.net/download-home-edition.html - select installer version.</p> <p>2) Unzip the folder you downloaded.</p> <p>3) Run the file ending in .msi - you'll get a windows prompt to install this, which it is safe to agree to. Install MobaXTerm in the default location, and you're then ready to log in.</p>"},{"location":"ssh/#logging-in-through-mobaxterm","title":"Logging in through MobaXTerm","text":"<p>1) Open MobaXTerm from the Windows start menu (if you can't find it, use the search bar).</p> <p>2) Click on Session in the upper left of MobaXTerm </p> <p></p> <p>3) Select SSH in the window that opens.</p> <p>4) In the next window, enter your computer's hostname in the <code>Remote host</code> box    (your computer's hostname is included in the email that we sent you with log     in details).</p> <p>5) In the same window, tick the <code>Specify username</code> box, and add your username     (included in the email that we sent you with log in details).</p> <p></p> <p>6) Tick OK, at the bottom of the box.</p> <p>7) You may see a message the first time you log in, saying that \"the authenticity of the host can not be established\", and asking if you wish to continue connecting. This message is normal when you log in to a new server. Agreeing will store the server's fingerprint, and the message will not appear again.</p> <p>8) Click on <code>Yes</code> if the message appears</p> <p></p> <p>9) You will then be asked for a password.</p> <pre><code>james@james.genomicscourse.com's password:\n</code></pre> <p>Type in the password that you've been emailed, and press enter. Nothing will appear while you type. If you know you have made a mistake, you can hold down backspace, and retype the password.</p> <p>10) Congratulations! You are now logged in!</p>"},{"location":"practicals/pt-1-read-cleaning/","title":"Part 1: Introduction To Genomic Data &amp; Read Cleaning","text":""},{"location":"practicals/pt-1-read-cleaning/#1-introduction","title":"1. Introduction","text":"<p>Cheap sequencing has created the opportunity to perform molecular-genetic analyses on almost anything! Traditional  model organisms including C. elegans, S. cerevisiae (Yeast) &amp; D. melanogaster (Fruit Fly) to name a few, benefited from years of efforts by expert genome assemblers, gene predictors, and curators. They have created most of the prerequisites for genomic analyses.</p> <p>In contrast, genomic resources are much more limited for those working on \"emerging\" model organisms or other species. These new organisms include most crops, animals and plant pest species, many pathogens, and major models for ecology &amp; evolution.</p> <p>The steps below are meant to provide some ideas that can help obtaining a reference genome and geneset of sufficient quality for many analyses. They are based on worked performed by the Wurm Lab who assembled the fire ant genome [1].</p> <p>In this pratical, the dataset you will use represents ~0.5% of the fire ant genome. This enables us to perform a toy/sandbox version of all analyses within a much shorter time than would normally be required. </p> <p>During this series of practicals, we will:</p> <ol> <li>Inspect and clean short (Illumina) reads,</li> <li>Perform genome assemble using our 'cleaned' data.  </li> <li>Assess the quality of our genome assembly. </li> <li>Identify protein-coding genes within our assembly. </li> <li>Assess the quality of gene predictions.</li> <li>Assess the quality of the entire process using a biologically meaningful measure.</li> </ol> <p>Note: Please do not jump ahead. You will gain the most by following through each section of the practical one by one. If you're fast, dig deeper into particular aspects. Dozens of approaches and tools exist for each step - try to understand their tradeoffs.</p>"},{"location":"practicals/pt-1-read-cleaning/#2-how-to-use-this-website","title":"2. How to use this website!","text":"<p>As you move through sections chronologically you will see some parts which are labelled acrcording to its intended purpose below: </p>"},{"location":"practicals/pt-1-read-cleaning/#general-text","title":"General text","text":"<p>Text which does not have any special formatting and looks (plain) like this will guide you through the practicals, providing background and explaining what anlyses we are performing, and why.</p>"},{"location":"practicals/pt-1-read-cleaning/#information-and-tips","title":"Information and tips","text":"<p>Info</p> <p>Text which appears in boxes of this colour aims to inform you of important information. </p>"},{"location":"practicals/pt-1-read-cleaning/#task","title":"Task","text":"<p>Task</p> <p>These boxes indicate there is something for you need to do! </p>"},{"location":"practicals/pt-1-read-cleaning/#code","title":"Code","text":"<pre><code>Text which appears in boxes of this colour will tell that you are looking at a terminal command.\nYou can copy and paste from here straight to the terminal but before you do take a moment to understand what the command is actually doing.\nSeveral command lines may be present, with each new line representing a single command. \n</code></pre> <p>Code windows are scrollable (horizontal &amp; verticle)</p>"},{"location":"practicals/pt-1-read-cleaning/#terminal-output","title":"Terminal output","text":"<p>Terminal output</p> <pre><code>Text appearing in these boxes represents output you might expect to see in the terminal in response to a command.\nCheck to see if you get a similar output!\n</code></pre> <p>Terminal windows are scrollable (horizontal &amp; verticle)</p>"},{"location":"practicals/pt-1-read-cleaning/#questions","title":"Questions","text":"<p>Question</p> <p>Text in these boxes will usually ask an open ended question. If you cannot think of an answer or you want to check you have the right one, do not hesitate to ask one of the demonstrators for help! </p> <p>Question</p> QuestionAnswer <p>Text in these boxes will ask a specific question. To reveal the answer select the 'Answer' tab.</p> <p>Here you will find the answer! </p> <p>Thats it! You are now ready to progress with the pratical! If you have any questions don't hesitate to ask one of the demonstrators for help. Good luck! </p>"},{"location":"practicals/pt-1-read-cleaning/#3-software-and-environment-setup","title":"3. Software and environment setup","text":""},{"location":"practicals/pt-1-read-cleaning/#test-that-the-necessary-bioinformatics-software-is-available","title":"Test that the necessary bioinformatics software is available","text":"<p>Task</p> <p>In the terminal run <code>seqtk</code>. </p> <p>The output of this command should look like this: </p> <p>Terminal output</p> <pre><code>Usage:   seqtk &lt;command&gt; &lt;arguments&gt;\nVersion: 1.4-r132-dirty\n\nCommand: seq       common transformation of FASTA/Q\n     size      report the number sequences and bases\n     comp      get the nucleotide composition of FASTA/Q\n     sample    subsample sequences\n     subseq    extract subsequences from FASTA/Q\n     fqchk     fastq QC (base/quality summary)\n     mergepe   interleave two PE FASTA/Q files\n     split     split one file into multiple smaller files\n     trimfq    trim FASTQ using the Phred algorithm\n</code></pre> <p>If you obtained a similar output move onto the next section!</p> <p>However, if you terminal output produces an error (like below), please ask a demonstrator for help! </p> <p>Terminal output</p> <pre><code>command not found\n</code></pre>"},{"location":"practicals/pt-1-read-cleaning/#set-up-directory-hierarchy-to-work-in","title":"Set up directory hierarchy to work in","text":"<p>Now we will start by creating a directory (folder) to work in! </p> <p>Drawing on ideas from Noble (2009)[2] and others, we recommend following a specific directory convention for all your projects. The details of the convention that we will use in this practical can be found here. For the purpose of this practical we will use a slightly simplified version of this structure which is now explained below.</p> <p>For each practical, you will have to create the following directory structure:</p> <ul> <li>A main directory in your home directory in the format   (<code>YYYY-MM-DD-name_of_the_practical</code>, where <code>YYYY</code> is the current year, <code>MM</code> is   the current month, and <code>DD</code> is the current day, and <code>name_of_the_practical</code>   matches the practical). For instance, on the 22nd of September 2025, you should   create the directory <code>2025-09-22-read_cleaning</code> for this practical.</li> <li>Inside this directory, create other three directories, called <code>input</code>, <code>tmp</code>,   and <code>results</code>.</li> <li>The directory <code>input</code> will contain the FASTQ files.</li> <li>The directory <code>tmp</code> will represent your working directory.</li> <li>The directory <code>results</code> will contain a copy of the final results.</li> </ul> <p>Task</p> <p>Now lets create the directory structure required for this practical!</p> <p>The command you will need is: <pre><code>mkdir 2025-09-22-read_cleaning\n</code></pre></p> <p>Now, see if you can make the necessary input, tmp and results subdirectories on your own!</p> <p>Info</p> <p>Each directory in which you have done something should include a <code>WHATIDID.txt</code> file in which you log your commands. </p> <p>Being disciplined about structuring analyses is extremely important. It is similar to having a laboratory notebook. It will prevent you from becoming overwhelmed by having too many files, or not remembering what you did where.</p> <p>Task</p> <p>To create our WHATIDID.txt file we can use the following command:</p> <pre><code>touch ./2025-09-22-read_cleaning/WHATIDID.txt\n</code></pre> <p>The to inspect the directory structure you have created you can run:</p> <pre><code>tree ./2025-09-22-read_cleaning\n</code></pre> <p>The expected terminal output is highlighted below </p> <p>Terminal</p> <pre><code>2025-09-22-read_cleaning\n\u251c\u2500\u2500 input\n\u251c\u2500\u2500 tmp\n\u251c\u2500\u2500 results\n\u2514\u2500\u2500 WHATIDID.txt\n</code></pre>"},{"location":"practicals/pt-1-read-cleaning/#4-sequencing-an-appropriate-sample","title":"4. Sequencing an appropriate sample","text":"<p>The properties of your data can affect the ability of bioinformatics algorithms to handle them. For instance, less diversity and complexity in a sample makes life easier: assembly algorithms really struggle when given similar sequences. So less heterozygosity and fewer repeats are easier.</p> <p>Thus:</p> <ul> <li>A haploid is easier than a diploid  (those of us working on haplo-diploid   Hymenoptera have it easy because male ants are haploid).</li> <li>It goes without saying that a diploid is easier than a tetraploid!</li> <li>An inbred line or strain is easier than a wild-type.</li> <li>A more compact genome (with less repetitive DNA) is easier than one full of   repeats - sorry, grasshopper &amp; tick researchers! ;)</li> </ul> <p>Many considerations go into the appropriate experimental design and sequencing strategy. We will not formally cover those here as this is a simple introduction and instead jump right into getting hands on with our data! </p>"},{"location":"practicals/pt-1-read-cleaning/#5-illumina-short-read-cleaning","title":"5. Illumina short-read cleaning","text":"<p>In this practical, we will work with paired ends short read sequences from an Illumina machine. Each piece of DNA was thus sequenced once from the 5' and once from the 3' end. Thus, we expect to have two files per sequence.</p> <p>However, sequencers aren't perfect. Several problems may affect the quality of the reads. You can find some examples here and here. </p> <p>Also, as you may already know, \"garbage in \u2013 garbage out\", which means that reads should be cleaned before performing any analysis.</p>"},{"location":"practicals/pt-1-read-cleaning/#setup-and-initial-inspection-using-fastqc","title":"Setup and initial inspection using FastQC","text":"<p>Lets move to the main directory for this practical, so that everything we need and do and create is in one place:</p> <p>Task</p> <pre><code># Remember that yours may have a different date, now or in future, so be careful to check if you copy-paste code\ncd ~/2025-09-22-read_cleaning\n</code></pre> <p>After, create a symbolic link (or symlink) using <code>ln -s</code> from the reads files to the <code>input</code> directory us the commands below:</p> <pre><code># Change directory to input\ncd input\n\n# Link the two compressed FASTQ files (remember that each correspond to one of\n# the pair)\nln -s /shared/data/reads.pe1.fastq.gz .\nln -s /shared/data/reads.pe2.fastq.gz .\n\n# Return to the main directory\ncd ..\n</code></pre> <p>Now run the <code>tree</code> command to inspect your directory structure. </p> <p>The structure of your directory should look like this:</p> <p>Terminal</p> <pre><code>2025-09-22-read_cleaning\n\u251c\u2500\u2500 input\n\u2502   \u251c\u2500\u2500 reads.pe1.fastq.gz -&gt; /shared/data/reads.pe1.fastq.gz\n\u2502   \u2514\u2500\u2500 reads.pe2.fastq.gz -&gt; /shared/data/reads.pe2.fastq.gz\n\u251c\u2500\u2500 tmp\n\u251c\u2500\u2500 results\n\u2514\u2500\u2500 WHATIDID.txt\n</code></pre> <p>Now, you can start evaluating the quality of the reads <code>reads.pe1.fastq.gz</code> and <code>reads.pe2.fastq.gz</code>. To do so, we will use FastQC (documentation). FastQC is a bioinformatics software tool to help visualise the characteristics of a sequencing run. It can thus inform your read cleaning a.k.a your quality control strategy.</p> <p>Task</p> <p>Run FastQC on the <code>reads.pe1.fastq.gz</code> and <code>reads.pe2.fastq.gz</code> files. The command is given below, where instead of <code>YOUR_OUTDIR</code>, you will need replace <code>YOUR_OUTDIR</code> with the path to your <code>tmp</code> directory (e.g. if you main directory is <code>2025-09-22-read_cleaning</code>, you need to replace <code>YOUR_OUTDIR</code> with <code>tmp</code>):</p> <pre><code>fastqc --nogroup --outdir YOUR_OUTDIR input/reads.pe1.fastq.gz\nfastqc --nogroup --outdir YOUR_OUTDIR input/reads.pe2.fastq.gz\n</code></pre> <p>The <code>--nogroup</code> option ensures that bases are not grouped together in many of the plots generated by FastQC. This makes it easier to interpret the output in many cases. The <code>--outdir</code> option is there to help you clearly separate input and output files. To learn more about these options run <code>fastqc --help</code> in the terminal.</p> <p>Important Note - Remember to log the commands you used in the <code>WHATIDID.txt</code> file. To do this you can use the text editors introduced in the UNIX practical including <code>nano</code></p> <p>Take a moment to verify your directory structure. You can do so using the <code>tree</code> command (be aware of your current working directory using the command <code>pwd</code>):</p> <pre><code>tree ~/2025-09-22-read_cleaning\n</code></pre> <p>The resulting directory structure should look like this:</p> <p>Terminal</p> <pre><code>2025-09-22-read_cleaning\n\u251c\u2500\u2500 input\n\u2502   \u251c\u2500\u2500 reads.pe1.fastq.gz -&gt; /shared/data/reads.pe1.fastq.gz\n\u2502   \u2514\u2500\u2500 reads.pe2.fastq.gz -&gt; /shared/data/reads.pe2.fastq.gz\n\u251c\u2500\u2500 tmp\n\u2502   \u251c\u2500\u2500 reads.pe1_fastqc.html\n\u2502   \u251c\u2500\u2500 reads.pe1_fastqc.zip\n\u2502   \u251c\u2500\u2500 reads.pe2_fastqc.html\n\u2502   \u2514\u2500\u2500 reads.pe2_fastqc.zip\n\u251c\u2500\u2500 results\n\u2514\u2500\u2500 WHATIDID.txt\n</code></pre> <p>If your directory and file structure looks different, ask for some help!</p>"},{"location":"practicals/pt-1-read-cleaning/#inspecting-fastqc-reports","title":"Inspecting FastQC Reports","text":"<p>Now lets inspect those FastQC report generated!</p> <p>Task</p> <p>First, copy the files <code>reads.pe1_fastqc.html</code> and <code>reads.pe2_fastqc.html</code> to the directory <code>~/www/tmp</code>. Then, open the browser and go to your personal module page (e.g., if your QMUL username is <code>bob</code>,  the URL will be <code>https://bob.genomicscourse.com</code>) and click on the <code>~/www/tmp</code> link. After that, click on one of the links corresponding to the reports files.</p> <p>Question</p> <p>Question: What does the FastQC report tell you? </p> <p>If in doubt, check the documentation here and what the quality scores mean here.</p> <p>For comparison, have a look at some plots from other sequencing libraries: e.g, [1], [2], [3]. Note, the results for your sequences may look different.</p> <p>Question</p> <p>Clearly, some sequences have very low quality bases towards the end. Why do you think that may be?</p> <p>Question</p> <p>Which FastQC plots shows the relationship between base quality and position in the sequence? What else does this plot tell you about nucleotide composition towards the end of the sequences?</p> <p>Question</p> <p>Should you maybe trim the sequences to remove low-quality ends? What else might you want to do?</p> <p>In the following sections, we will perform two cleaning steps:</p> <ul> <li>Trimming the ends of sequence reads using cutadapt.</li> <li>K-mer filtering using the bioinformatics tool kmc3.</li> <li>Removing sequences that are of low quality or too short using cutadapt.</li> </ul> <p>Other similar tools include fastx_toolkit, BBTools, and Trimmomatic however, we will not use them in this practical!</p>"},{"location":"practicals/pt-1-read-cleaning/#read-trimming","title":"Read trimming","text":"<p>To clean the FASTQ sequences, we will use a software tool called cutadapt. As stated on the official website:</p> <ul> <li>Cutadapt finds and removes adapter sequences, primers, poly-A tails and other types of unwanted sequence from your high-throughput sequencing reads.</li> </ul> <p>Specifically, we will use <code>cutadapt</code> to trim the sequences.</p> <p>Question</p> <p>What is the meaning of <code>cutadapt</code> options <code>--cut</code> and <code>--quality-cutoff</code> ? (Hint: you can read a short description of the options by calling the command <code>cutadapt -h</code>)</p> <p>To identify relevant quality cutoffs, it is necessary to be familiar with base quality scores and examine the per-base quality score in your FastQC report.</p> <p>We will run <code>cutadapt</code> with two options, <code>--cut</code> and/or <code>--quality-cutoff</code>, corresponding to the number of nucleotides to trim from the beginning (<code>--cut</code>) and end (<code>--quality-cutoff</code>) of the sequences.</p> <p>Info</p> <p>Note: If you trim too much of your sequence (i.e., too large values for <code>--cut</code> and <code>--quality-cutoff</code>), you increase the likelihood of eliminating important information. Additionally, if the trimming is too aggressive, some sequences may be discarded completely, which will cause problems in the subsequent steps of the pre-processing. For this example, we suggest to keep <code>--cut</code> below 5 and <code>--quality-cutoff</code> below 10.</p> <p>Task</p> <p>The command to run <code>cutadapt</code> on the two reads files is reported below, where <code>BEGINNING</code> and <code>CUTOFF</code> are the the two integer values corresponding to the number of bases to trim from the beginning of the sequence and the quality threshold (see the above info note for suggestion about the values to use).  Remember that each <code>.fq</code> file can have a different set of values.</p> <pre><code>cd ~/2025-09-22-read_cleaning\n\ncutadapt --cut BEGINNING --quality-cutoff CUTOFF input/reads.pe1.fastq.gz &gt; tmp/reads.pe1.trimmed.fq\n\ncutadapt --cut BEGINNING --quality-cutoff CUTOFF input/reads.pe2.fastq.gz &gt; tmp/reads.pe2.trimmed.fq\n</code></pre>"},{"location":"practicals/pt-1-read-cleaning/#6-k-mer-filtering-removal-of-short-sequences","title":"6. K-mer filtering, removal of short sequences","text":"<p>Let's suppose that you have sequenced your sample at 45x genome coverage. This means that every nucleotide of the genome was sequenced 45 times on average. So, for a genome of 100,000,000 nucleotides, you expect to have about 4,500,000,000 nucleotides of raw sequence. But that coverage will not be homogeneous.  Instead, the real coverage distribution will be influenced by factors including DNA quality,  library preparation type, how was DNA packaged within the chromosomes (e.g., hetero vs. euchromatin) and local GC content. But you might expect most of the genome to be covered between 20 and 70x.</p> <p>In practice, this distribution can be very strange. One way of rapidly examining the coverage distribution before you have a reference genome is to chop your raw sequence reads into short \"k-mers\" of k nucleotides long, and estimate the frequency of occurrence of all k-mers. An example plot of k-mer frequencies from a haploid sample sequenced at ~45x coverage is shown below:</p> <p></p> <p>In the above plot, the y axis represents the proportion of k-mers in the dataset that are observed x times (called Coverage). As, expected, we observe a peak in the region close to 45, which corresponds to the targeted coverage.</p> <p>However, we also see that a large fraction of sequences have a very low coverage (they are found only 10 times or less).</p> <p>These rare k-mers are likely to be errors that appeared during library preparation or sequencing, or could be rare somatic mutations. Analogously (although not shown in the above plot) other k-mers may exist at very large coverage (up to 10,000). These could be viruses or other pathogens, or highly  repetitive parts of the genome, such as transposable elements or simple repeats.</p> <p>Info</p> <p>Note: Extremely rare and extremely frequent sequences can both confuse assembly algorithms. Eliminating them can reduce subsequent memory, disk space and CPU requirements considerably, making overall computing more efficient and friendly.</p> <p>Below, we use kmc3 to \"mask\" extremely rare k-mers (i.e., convert each base in the sequences corresponding to rare k-mers into N). In this way, we will ignore these bases (those called N) because they are not really present in the species. Multiple alternative approaches for k-mer filtering exist (e.g., using khmer).</p> <p>Here, we use kmc3 to estimate the coverage of k-mers with a size of 21 nucleotides. When the masked k-mers are located at the end of the reads, we trim them in a subsequent step using cutadapt. If the masked k-mers are in the middle of the reads, we leave them just masked. Trimming reads (either masked k-mers or low quality ends in the previous step) can cause some reads to become too short to be informative. We remove such reads in the same step using cutadapt. Finally, discarding reads (because they are too short) can cause the corresponding read of the pair to become \"unpaired\". While it is possible to capture and use unpaired reads, we skip that here for simplicity. Understanding the exact commands \u2013 which are a bit convoluted \u2013 is unnecessary. However, it is important to understand the concept of k-mer filtering and the reasoning behind each step.</p> <p>Task</p> <p>To mask rare k-mers we will first build a k-mer database that includes counts for each k-mer. For this, we first make a list of files to input to KMC.</p> <pre><code>ls tmp/reads.pe1.trimmed.fq tmp/reads.pe2.trimmed.fq &gt; tmp/file_list_for_kmc\n</code></pre> <p>Build a k-mer database using k-mer size of 21 nucleotides (-k). This will produce two files in your <code>tmp/</code> directory: <code>./tmp/21-mers.kmc_pre</code> and <code>./tmp/21-mers.kmc_suf</code>. The last argument (tmp) tells kmc where to put intermediate files during computation; these are automatically deleted afterwards. The -m option tells KMC to use only 4 GB of RAM.</p> <pre><code>kmc -m4 -k21 @tmp/file_list_for_kmc tmp/21-mers tmp\n</code></pre> <p>Mask k-mers (-hm) observed less than two times (-ci) in the database (tmp/21-mers). The -t option tells KMC to run in single-threaded mode: this is required to preserve the order of the reads in the file. filter is a sub-command of kmc_tools that has options to mask, trim, or discard reads contain extremely rare k-mers.</p> <p>Note: kmc_tools command may take a few seconds to complete and does not provide any visual feedback during the process.</p> <pre><code>kmc_tools -t1 filter -hm tmp/21-mers tmp/reads.pe1.trimmed.fq -ci2 tmp/reads.pe1.trimmed.norare.fq\n\nkmc_tools -t1 filter -hm tmp/21-mers tmp/reads.pe2.trimmed.fq -ci2 tmp/reads.pe2.trimmed.norare.fq\n</code></pre> <p>Check if unpaired reads are present in the files</p> <pre><code>cutadapt -o /dev/null -p /dev/null tmp/reads.pe1.trimmed.norare.fq tmp/reads.pe2.trimmed.norare.fq\n</code></pre> <p>Trim 'N's from the ends of the reads, then discard reads shorter than 21 bp, and save remaining reads to the paths specified by -o and -p options. The -p option ensures that only paired reads are saved (an error is raised if unpaired reads are found).</p> <pre><code>cutadapt --trim-n --minimum-length 21 -o tmp/reads.pe1.clean.fq -p tmp/reads.pe2.clean.fq tmp/reads.pe1.trimmed.norare.fq tmp/reads.pe2.trimmed.norare.fq\n</code></pre> <p>Finally, we can copy over the cleaned reads to results directory for further analysis</p> <pre><code>cp tmp/reads.pe1.clean.fq tmp/reads.pe2.clean.fq results\n</code></pre>"},{"location":"practicals/pt-1-read-cleaning/#inspecting-quality-of-cleaned-reads","title":"Inspecting quality of cleaned reads","text":"<p>Now we have cleaned our reads, lets have a look at how the 'cleaned' file is different from the original! </p> <p>Question</p> <p>Which percentage of reads have we removed overall? (hint: <code>wc -l</code> can count lines in a non-gzipped file).  </p> <p>If you have time, maybe rerun FastQC on the cleaned data and inspect the output!  </p>"},{"location":"practicals/pt-1-read-cleaning/#7-references","title":"7. References","text":"<ol> <li> <p>Wurm, Y., Wang, J., Riba-Grognuz, O., Corona, M., Nygaard, S., Hunt, B.G.,    Ingram, K.K., Falquet, L., Nipitwattanaphon, M., Gotzek, D. and Dijkstra,    M.B., 2011. The genome of the fire ant Solenopsis invicta. Proceedings of the 2012.    National Academy of Sciences, 108(14), pp.5679-5684.</p> </li> <li> <p>Noble, W.S., 2009. A quick guide to organizing computational biology    projects. PLoS computational biology, 5(7), p.e1000424.</p> </li> </ol>"},{"location":"practicals/pt-1-read-cleaning/#8-further-reading","title":"8. Further reading","text":"<ul> <li> <p>MARTIN Marcel. Cutadapt removes adapter sequences from high-throughput   sequencing reads. EMBnet.journal, [S.l.], v. 17, n. 1, p. pp. 10-12, may 2011.   ISSN 2226-6089. doi: https://doi.org/10.14806/ej.17.1.200.</p> </li> <li> <p>Kokot, M., D\u0142ugosz, M. and Deorowicz, S., 2017. KMC 3: counting and   manipulating k-mer statistics. Bioinformatics, 33(17), pp.2759-2761.</p> </li> </ul>"},{"location":"practicals/pt-1-read-cleaning/#9-bonus-questions-if-youre-done-early","title":"9. Bonus questions if you're done early","text":"<p>Question</p> <ul> <li>Which read cleaners exist and are the most popular today? </li> <li>Which read cleaners would you use for Illumina data? Why?</li> <li>Which read cleaners would you use for long-read data? Why?</li> <li>Can having an existing genome assembly help with read cleaning? How?</li> </ul>"},{"location":"practicals/pt-2-assembly/","title":"Part 2: Genome assembly","text":"<p>You need to have gone through Part 1: Read cleaning before starting this practical.</p>"},{"location":"practicals/pt-2-assembly/#1-a-brief-assembly-example","title":"1. A brief assembly example","text":"<p>Many different pieces of software exist for genome assembly but as mentioned in the earlier lectures we will be using SPAdes. </p> <p>Again for this practical you will be using the remote AWS computers created for you so please ssh back into these! </p> <p>Task</p> <p>Following the same procedure from the first read cleaning practical   Part 1: Read cleaning, create a new main directory for today's practical (e.g., <code>2025-09-23-assembly</code>), the <code>input</code>, <code>tmp</code>, and <code>results</code> subdirectories, and the file <code>WHATIDID.txt</code> to log your commands. </p> <p>To help get you started    <pre><code>mkdir 2025-09-23-assembly\n</code></pre></p> <p>Your directory hierarchy should look like the following</p> <p>Terminal</p> <pre><code>2025-09-23-assembly\n\u251c\u2500\u2500 input\n\u251c\u2500\u2500 tmp\n\u251c\u2500\u2500 results\n\u2514\u2500\u2500 WHATIDID.txt\n</code></pre> <p>Next lets link the cleaned reads from yesterdays practical into our <code>input</code> subdirectory. We will be using these clean reads to create our assembly today! </p> <p>Task</p> <p>Use the following commands to achieve this!    <pre><code>cd ~/2025-09-23-assembly\ncd input\nln -s ~/2025-09-22-read_cleaning/results/reads.pe*.clean.fq .\ncd ..\n</code></pre></p> <p>Question</p> <ul> <li>Did you note the use of <code>*</code> in the above command?</li> <li>What does it do? (Hint: the symbol <code>*</code> is called a wildcard)</li> </ul> <p>Task</p> <p>To assemble our cleaned reads with SPAdes, run the following line:    (This will take about 10 minutes - please complete the task below in this time)</p> <pre><code>spades.py -o tmp -1 input/reads.pe1.clean.fq -2 input/reads.pe2.clean.fq\n</code></pre> <p>Like any other assembler, SPAdes creates many files, including a    <code>scaffolds.fasta</code> file that is likely to be used for follow-up    analyses.  </p> <p>Copy this file to your <code>results</code> directory:</p> <pre><code>cp tmp/scaffolds.fasta results/\n</code></pre> <p>Take a look at the contents of this file (e.g., to see the first 10 lines, use    <code>head results/scaffolds.fasta</code>, or <code>tail results/scaffolds.fasta</code> to see the   last 10 lines).</p> <p>Question</p> <p>Does it contain a lot of NNNN sequences? What do you think might be the reason for that? (Do not worry if your assembly does not contain any NNNN sequence.</p> <p>Task</p> <p>While waiting for spades to run please move on to the Accessing Apocrita practical. </p> <p>To get an idea of some challenges associated to _de novo_genome assembly and the approaches used to overcome them from the following papers:</p> <ul> <li>Towards complete and error-free genome assemblies of all vertebrate species. (Rhie et al 2021)</li> <li>Long walk to genomics: History and current approaches to genome sequencing and assembly. (Giani et al 2020).</li> <li>A hybrid approach for de novo human genome sequence assembly and phasing. Mostovoy et al (2016).</li> <li>Genetic variation and the de novo assembly of human genomes. Chaisson et al 2015 NRG</li> </ul>"},{"location":"practicals/pt-2-assembly/#2-quality-assessment","title":"2. Quality assessment","text":"<p>How do we know if our genome is good?</p> <p>\"... the performance of different de novo genome assembly algorithms can  vary greatly on the same dataset, although it has been repeatedly demonstrated that no single assembler is optimal in every possible quality metric  [6, 7, 8]. The most widely used metrics for evaluating an assembly include 1) contiguity statistics such as scaffold and contig N50 size, 2) accuracy statistics such as the number of structural errors found when compared with an available reference genome (GAGE (Genome Assembly Gold Standard Evaluation) evaluation tool [8]), 3) presence of core eukaryotic genes (CEGMA (Core  Eukaryotic Genes Mapping Approach) [9]) or, if available, transcript mapping rates, and 4) the concordance of the sequence with remapped paired-end and mate-pair reads (REAPR (Recognizing Errors in Assemblies using Paired Reads)  [10], assembly validation [11], or assembly likelihood [12]).\" -  Wences &amp; Schatz (2015)</p>"},{"location":"practicals/pt-2-assembly/#21-simple-metrics","title":"2.1 Simple metrics","text":"<p>An assembly software will generally provide some statistics about what it did. But, note that the output formats may differ between assemblers.  Quast, the Quality Assessment Tool for Genome Assemblies is a tool designed to generate a standardized report.</p> <p>Task</p> <p>Run Quast on the <code>scaffolds.fasta</code>   file without special options to get the basic statistics:</p> <pre><code>cd ~/2025-09-23-assembly/results\nquast.py scaffolds.fasta\n</code></pre> <p>Have a look at the report (pdf or html) generated by Quast (copy the Quast's   output directory to <code>~/www/tmp</code> and access through your browser).</p> <pre><code>cp quast_results/latest/report.html ~/www/tmp\n</code></pre> <p></p> <p>Question</p> <ul> <li>What do the values in the table mean?</li> <li>For which values is higher better, and for which ones is smaller better?</li> </ul> <p>In some cases, we have prior knowledge about the expected percentage of GC  content, the number of chromosomes, and the total genome size. This information can be compared to the statistics present in Quast's report.</p> <p>Task</p> <p>See if you can find the expected GC content of the complete Fire Ant genome? Does the GC content of the assembly match what is expected? </p>"},{"location":"practicals/pt-2-assembly/#22-biologically-meaningful-measures","title":"2.2 Biologically meaningful measures","text":"<p>Unfortunately, with many of the simple metrics, it is difficult to determine whether the assembler did things correctly, or just haphazardly stuck lots of reads together.</p> <p>We often have other prior information about what to expect in this genome. For example:</p> <ol> <li>if we have a reference assembly from a not-too-distant relative, we can     expect that large genome parts will be organised in the same order, i.e.,      synteny.</li> <li>If we independently created a transcriptome assembly, we can expect that     the exons making each transcript will be mapped sequentially onto the      genome (see TGNet for an implementation).</li> <li>We can expect different patterns of gene content and structure between     eukaryotes and prokaryotes.</li> <li>Pushing this idea further, we can expect a genome to contain a single copy     of each of the \"house-keeping\" genes found in related species. This is      applied in BUSCO (Benchmarking Universal Single-Copy Orthologs).     Note that:<ul> <li>BUSCO is a refined, modernized implementation of CEGMA    (Core Eukaryotic Genes Mapping Approach). CEGMA examines a eukaryotic   genome assembly for the presence and completeness of 248 \"core eukaryotic genes\".</li> <li>Quast also includes a \"quick and dirty\" method of finding genes.</li> </ul> </li> <li>We can expect that the different scaffolds in the genome have a unimodal       distribution in sequence read coverage. Similarly, we can expect that the       percentage of GC content will be unimodally distributed among scaffolds. Using this idea, the Blobology approach determined that evidence of foreign sequences in Tardigrades is largely due to extensive contamination rather than extensive horizontal gene transfer Koutsovoulos et al 2016.</li> </ol> <p>It is important to understand the concepts underlying these different  approaches.</p>"},{"location":"practicals/pt-2-assembly/#3-in-your-own-time","title":"3. In your own time","text":"<p>Try to figure out what are the tradeoffs between de bruijn graph and  overlap-layout-consensus assembly approaches.</p>"},{"location":"practicals/pt-3-prediction/","title":"Part 3: Gene Prediction","text":"<p>You need to have gone through Part 2: Genome assembly before starting this practical.</p> <p>Many tools exist for gene prediction, some based on ab initio statistical models of what a protein-coding gene should look like, others that use similarity with protein-coding genes from other species, and others such as Augustus and SNAP, which use both.  </p> <p>Info</p> <p>There is no perfect tool or approach, thus we typically run many gene-finding tools and call a consensus between the different predicted gene models. </p> <p>Pipelines which combine the use of multiople tools include: </p> <ul> <li>MAKER, </li> <li>BRAKER </li> <li>JAMg </li> </ul> <p>In this practical, we will use [MAKER]((http://www.yandell-lab.org/software/maker.html) and again for this practical you will be using the remote AWS computers created for you so please ssh back into these! </p>"},{"location":"practicals/pt-3-prediction/#1-running-maker","title":"1. Running Maker","text":"<p>Task</p> <p>Following the same procedure from the first read cleaning practical   Part 1: Read cleaning, create a new main directory for today's practical (e.g., <code>2025-09-24-gene_prediction</code>), the <code>input</code>, <code>tmp</code>, and <code>results</code> subdirectories, and the file <code>WHATIDID.txt</code> to log your commands. </p> <p>To help get you started    <pre><code>mkdir 2025-09-24-gene_prediction\n</code></pre></p> <p>Your directory hierarchy should look like the following</p> <p>Terminal</p> <pre><code>2025-09-24-gene_prediction\n\u251c\u2500\u2500 input\n\u251c\u2500\u2500 tmp\n\u251c\u2500\u2500 results\n\u2514\u2500\u2500 WHATIDID.txt\n</code></pre> <p>Next lets link your assembled scaffolds from from yesterdays practical into our <code>input</code> subdirectory. We will be using MAKER to annotate this assembly! </p> <p>Task</p> <p>Link the output (assembly) from Part 2 practical into <code>input</code> subdirectory:</p> <pre><code>cd ~/2025-09-24-gene_prediction/input\nln -s ~/2025-09-23-assembly/results/scaffolds.fasta .\ncd ..\n</code></pre> <p>Next we are going to pull out the longest few scaffolds from our assembly and create a new file to house these.</p> <p><pre><code>seqtk seq -L 10000 input/scaffolds.fasta &gt; tmp/min10000.fa\n</code></pre> Gene prediction can be difficult if the assembly is low quality and does not include long scaffolds (remember, trash in = trash out). For instance, in the case of short scaffolds, if a gene is 2,000 bp long and includes introns, it may be very hard to find many entire genes. Thats why with the command above we are only carrying forward sequences that are longer than 10kb in length.   </p> <p>Info</p> <p>Note: If you have difficulty in predicting the genes or you suspect that your assembly may be affected by the aforementioned issues, you can use already assembled scaffolds. <pre><code># Link this scaffolds file into your input directory\nln -s /shared/data/backup_assembly/scaffolds.fasta .\n</code></pre></p> <p>In the rest of this practical, we will show how to run MAKER in a simple scenario. For a better understanding of how this tool works, and how it can be applied in real-case scenarios,  we strongly encourage to read the paper and documentation. Also, checking which settings were used in recent publications can be very helpful for reproducing (or critiquing) analyses. </p> <p>Info</p> <p>Here is a link to the MAKER documentation </p> <p>Question</p> <p>What bioinformatic tools is MAKER implementing in it genome annotation pipeline? </p> <p>Task</p> <p>Now change to your <code>tmp</code> directory and lets start the process of running the <code>maker</code> pipeline:</p> <p><pre><code>cd tmp\nmaker -OPTS\n</code></pre> This will generate an empty <code>maker_opts.ctl</code> configuration file (ignore the warnings). Edit that file using a text editor such as <code>nano</code> and specify:</p> <ul> <li>genome: <code>min10000.fa</code></li> <li>deactivate RepeatMasker by changing <code>model_org</code> line to <code>model_org=</code>    (i.e., nothing afer <code>=</code>)</li> <li>deactivate RepeatRunner by changing <code>repeat_protein</code> line to    <code>repeat_protein=</code> (i.e., nothing after <code>=</code>)</li> <li>Augustus_species:<code>honeybee1</code> (remember to add 1 at the end; this provides   hints to Augustus about the gene structure based on what we know about gene composition from the honeybee.</li> </ul> <p>We deactivated RepeatMakser and RepeatRunner due to computational limitations as well as the lack of a suitable library of repetitive elements for this species. For a real project, we would include RepeatMasker, likely after  creating a new repeat library for our species. For a real project, we would also include gene expression data (RNAseq improves gene prediction performance tremendously), protein sequences from related species, and iteratively train gene prediction algorithms (e.g., Augustus and SNAP) for our data.</p> <p>After making the necessary edits we can inspect the <code>maker_opts.ctl</code> by printing it to stout using the following command, allowing us to double check the edits we have made are correct!</p> <p><pre><code>cat maker_opts.ctl\n</code></pre> The expected terminal output is shown below.</p> <p>Terminal</p> <pre><code>#-----Genome (these are always required)\ngenome=min10000.fa\norganism_type=eukaryotic #eukaryotic or prokaryotic. Default is eukaryotic\n\n#-----Re-annotation Using MAKER Derived GFF3\nmaker_gff= #MAKER derived GFF3 file\nest_pass=0 #use ESTs in maker_gff: 1 = yes, 0 = no\naltest_pass=0 #use alternate organism ESTs in maker_gff: 1 = yes, 0 = no\nprotein_pass=0 #use protein alignments in maker_gff: 1 = yes, 0 = no\nrm_pass=0 #use repeats in maker_gff: 1 = yes, 0 = no\nmodel_pass=0 #use gene models in maker_gff: 1 = yes, 0 = no\npred_pass=0 #use ab-initio predictions in maker_gff: 1 = yes, 0 = no\nother_pass=0 #passthrough anyything else in maker_gff: 1 = yes, 0 = no\n\n#-----EST Evidence (for best results provide a file for at least one)\nest= #set of ESTs or assembled mRNA-seq in fasta format\naltest= #EST/cDNA sequence file in fasta format from an alternate organism\nest_gff= #aligned ESTs or mRNA-seq from an external GFF3 file\naltest_gff= #aligned ESTs from a closly relate species in GFF3 format\n\n#-----Protein Homology Evidence (for best results provide a file for at least one)\nprotein=  #protein sequence file in fasta format (i.e. from mutiple organisms)\nprotein_gff=  #aligned protein homology evidence from an external GFF3 file\n\n#-----Repeat Masking (leave values blank to skip repeat masking)\nmodel_org= \nrmlib= #provide an organism specific repeat library in fasta format for RepeatMasker\nrepeat_protein=\nrm_gff= #pre-identified repeat elements from an external GFF3 file\nprok_rm=0 #forces MAKER to repeatmask prokaryotes (no reason to change this), 1 = yes, 0 = no\nsoftmask=1 #use soft-masking rather than hard-masking in BLAST (i.e. seg and dust filtering)\n\n#-----Gene Prediction\nsnaphmm= #SNAP HMM file\ngmhmm= #GeneMark HMM file\naugustus_species=honeybee1\nfgenesh_par_file= #FGENESH parameter file\npred_gff= #ab-initio predictions from an external GFF3 file\nmodel_gff= #annotated gene models from an external GFF3 file (annotation pass-through)\nrun_evm=0 #run EvidenceModeler, 1 = yes, 0 = no\nest2genome=0 #infer gene predictions directly from ESTs, 1 = yes, 0 = no\nprotein2genome=0 #infer predictions from protein homology, 1 = yes, 0 = no\ntrna=0 #find tRNAs with tRNAscan, 1 = yes, 0 = no\nsnoscan_rrna= #rRNA file to have Snoscan find snoRNAs\nsnoscan_meth= #-O-methylation site fileto have Snoscan find snoRNAs\nunmask=0 #also run ab-initio prediction programs on unmasked sequence, 1 = yes, 0 = no\nallow_overlap= #allowed gene overlap fraction (value from 0 to 1, blank for default)\n\n#-----Other Annotation Feature Types (features MAKER doesn't recognize)\nother_gff= #extra features to pass-through to final MAKER generated GFF3 file\n\n#-----External Application Behavior Options\nalt_peptide=C #amino acid used to replace non-standard amino acids in BLAST databases\ncpus=1 #max number of cpus to use in BLAST and RepeatMasker (not for MPI, leave 1 when using MPI)\n\n#-----MAKER Behavior Options\nmax_dna_len=100000 #length for dividing up contigs into chunks (increases/decreases memory usage)\nmin_contig=1 #skip genome contigs below this length (under 10kb are often useless)\n\npred_flank=200 #flank for extending evidence clusters sent to gene predictors\npred_stats=0 #report AED and QI statistics for all predictions as well as models\nAED_threshold=1 #Maximum Annotation Edit Distance allowed (bound by 0 and 1)\nmin_protein=0 #require at least this many amino acids in predicted proteins\nalt_splice=0 #Take extra steps to try and find alternative splicing, 1 = yes, 0 = no\nalways_complete=0 #extra steps to force start and stop codons, 1 = yes, 0 = no\nmap_forward=0 #map names and attributes forward from old GFF3 genes, 1 = yes, 0 = no\nkeep_preds=0 #Concordance threshold to add unsupported gene prediction (bound by 0 and 1)\n\nsplit_hit=10000 #length for the splitting of hits (expected max intron size for evidence alignments)\nmin_intron=20 #minimum intron length (used for alignment polishing)\nsingle_exon=0 #consider single exon EST evidence when generating annotations, 1 = yes, 0 = no\nsingle_length=250 #min length required for single exon ESTs if 'single_exon is enabled'\ncorrect_est_fusion=0 #limits use of ESTs in annotation to avoid fusion genes\n\ntries=2 #number of times to try a contig if there is a failure for some reason\nclean_try=0 #remove all data from previous run before retrying, 1 = yes, 0 = no\nclean_up=0 #removes theVoid directory with individual analysis files, 1 = yes, 0 = no\nTMP= #specify a directory other than the system default temporary directory for temporary files\n</code></pre> <p>Task</p> <p>Now our configuration file is ready, run MAKER! </p> <p><pre><code>maker maker_opts.ctl\n</code></pre> This may take a few minutes, depending on how much data you gave it:</p> <p>Genome annotation software like MAKER usually provide information about the  exon-intron structure of the genes (e.g., in  GFF3 format), and sequence of corresponding messenger RNA and protein products (e.g., in FASTA format).</p> <p>Task</p> <p>While MAKER is running, note the different file formats you have encountered throughout this module up until now.</p> <p>Question</p> <ul> <li>What is the difference between a .fq.gz and .fq file?</li> <li>What information does the 5th column in a GFF file contain?  </li> </ul> <p>Once MAKER has finished running the results will be hidden in subdirectories of  <code>min10000.maker.output</code>. MAKER provides a helper script to collect this hidden outputs all in one place (again please ignore the warnings for these steps):</p> <p>Task</p> <p>Run the following commands to pull out information about exon-intron structure of the predicted genes. This will be saved to the file min10000.all.gff.</p> <pre><code>gff3_merge -d min10000.maker.output/min10000_master_datastore_index.log\n</code></pre> <p>Next, pull out predicted messenger RNA and protein sequences.  <pre><code>fasta_merge -d min10000.maker.output/min10000_master_datastore_index.log\n</code></pre></p> <p>These will be saved to the files: <code>min10000.all.maker.augustus.transcripts.fasta</code> and <code>min10000.all.maker.augustus.proteins.fasta</code></p>"},{"location":"practicals/pt-3-prediction/#2-quality-control-of-individual-genes","title":"2. Quality control of individual genes","text":"<p>So now we have some gene predictions... how can we know if they are any good?</p> <p>The easiest way to get a feel for this is to use the following example sequences: predicted protein sequences from rice and honeybee.</p> <p>We will compare them using BLAST to known sequences from other species against the Swissprot database (faster), or the Uniref50 database (slower).</p>"},{"location":"practicals/pt-3-prediction/#21-running-blast-with-sequenceserver","title":"2.1 Running BLAST with SequenceServer","text":"<p>We will use SequenceServer to run the BLAST search!</p> <p>Task</p> <p>Open genomicscourse.sequenceserver.com in a new tab in your browser, paste the example rice and honeybee protein sequences in the textbox.</p> <p>On the right hand side, under protein database select Non-redundant UniProtKB/SwissProt sequences as the database to use! </p> <p>The image below is what your browser window should look like! </p> <p></p> <p>Then click on the 'BLAST' button to begin the BLAST search. This will take a minute or two and the window will look like: </p> <p></p> <p>Once the analysis is complete you will get a output report like below: </p> <p></p> <p>This report contains a lot of information, but dont be overwhelmed! Focus solely on the alignment section and you can toggle between alignments by selecting either the rice or honeybee sequencing in the top left hand side (as highlighted in red below)</p> <p></p> <p>Now in you own time, examin the report and try to answer the questions below! </p> <p>Question</p> QuestionAnswer <p>What sequence is the rice_spQ7F1X5 sequence most similar too?</p> <p>sp|Q7F1X5.1|RecName: Full=4-coumarate--CoA ligase-like 5 [Oryza sativa Japonica Group] with 100% query coverage and 100% identity. </p> <p>Question</p> QuestionAnswer <p>What sequence is ApisMellifera_SequenceA sequence most similar too?</p> <p>sp|Q90ZA1.1| RecName: Full=Poly(A)-specific ribonuclease PARN; AltName: Full=Deadenylating nuclease; AltName: Full=Deadenylation nuclease; AltName: Full=Polyadenylate-specific ribonuclease; AltName: Full=parn-A [Xenopus laevis] with 40% query coverage and 42.4% identity. </p> <p>Question</p> <p>Look at the full report for the two given gene predictions, do you they are complete, or can you infer from the BLAST alignments that something may be wrong? Start by comparing the length of your gene prediction to that of the BLAST hits alongside other metrics such as identity.  </p> <p>Task</p> <p>Now try a few of your gene predictions. To do this you can use the predicted protein sequences which you generated and which can be found in <code>min10000.all.maker.augustus.proteins.fasta</code>. </p> <p>Note - Run BLAST on only a maximum of 12 sequences at a time (instead of simply selecting the first 12 genes in your file, copy-paste sequences randomly from  the file). See if you can tell if based on the SequencingServer report generated the quality of the genome annotation!</p> <p>As you can see, gene prediction software is imperfect. This is even the case when using all available evidence. This is potentially costly for analyses that rely on gene predictions, i.e. many of the analyses we might want to do:</p> <p>\u201cIncorrect annotations [ie. gene identifications] poison every experiment  that makes use of them. Worse still the poison spreads.\u201d \u2013  Yandell &amp; Ence (2012).</p>"},{"location":"practicals/pt-3-prediction/#22-using-genevalidator","title":"2.2 Using GeneValidator","text":"<p>The GeneValidator tool can help to evaluate the quality of a gene prediction by comparing features of a predicted gene to similar database sequences. This approach expects that similar sequences should for example be of similar length. Genevalidator was built to automate the comparison of sequence characteristics similarly to what we just did through visual individual BLAST results.</p> <p>Task</p> <p>Try to run the example rice and honeybee protein sequences through GeneValidator. It should be accessible at https://genevalidator.genomicscourse.com/ or https://genevalidator.wurmlab.com/. </p> <p>Copy and paste the xample rice and honey bee sequences into the input text box as shown in the image below. </p> <p></p> <p>This make take a few minutes to complete, but on completion the results will appear in the section below. Take a look through the results page along with the original GeneValidator publication (link here) to inspect the proteins generated as part of the gene sequence.</p> <p></p> <p>Question</p> QuestionAnswer <p>Why is it important to consider the Length Cluster Metric?</p> <p>When hovering over the metric we get the definition: Check whether the prediction length fits most of the BLAST hit lengths, by 1D hierarchical clusterization.</p> <p>So it is a way to see if the predicted gene length makes sense by comparing it to the lengths of BLAST matches. The method groups BLAST hit lengths into clusters, then reports:</p> <ul> <li>The predicted length of the query. </li> <li>The main length range where most BLAST hits fall.</li> </ul> <p>If the predicted length is inside that main range, it\u2019s probably accurate.</p> <p>Task</p> <p>By selecting the image icon on the right hand side of each query (cirlced in red) you will open the drop down section to see the associated plots. </p> <p></p> <p>Now take a look at some of your protein predictions from your own MAKER genome annotation run! How do they look? Can you tell the difference between a good and a bad prediction? </p> <p>Question</p> QuestionAnswer <p>What is the purpose of the Gene Merge Validation Plot?</p> <p>First lets break down the abbreviations used: </p> <p>What HSP means</p> <ul> <li>HSP (High-Scoring Pair) = a stretch of similarity found by BLAST between your query sequence and a database sequence.</li> <li> <p>Each HSP has:</p> <ul> <li>A start coordinate (where the match begins on the query).</li> <li>An end coordinate (where the match stops on the query).</li> </ul> </li> </ul> <p>What the graph shows</p> <ul> <li>X-axis (Start Offset): where the HSP begins on the query sequence (further right = later in the sequence).</li> <li>Y-axis (End Offset): where the HSP ends on the query sequence (higher = later in the sequence).</li> <li>Each red dot = one HSP, plotted by its start (x) and end (y) positions.</li> </ul> <p>How to interpret this graph</p> <ul> <li>If all HSPs lined up diagonally in a single cluster, that would suggest they all map to one continuous region (a single gene).</li> </ul>"},{"location":"practicals/pt-3-prediction/#3-comparing-whole-genesets-and-prioritizing-genes-for-manual-curation","title":"3. Comparing whole genesets and prioritizing genes for manual curation","text":"<p>Genevalidator's visual output can be handy when looking at a few genes. But the  tool also provides tab-delimited output, useful when working in the command-line or running the software on whole proteomes. This can help the analysis:</p> <ul> <li>In situations when you can choose between multiple gene sets.</li> <li>To identify which gene predictions are likely correct, and which predictions     need might require further inspection and potentially be manually fixed.</li> </ul>"},{"location":"practicals/pt-3-prediction/#4-manual-curation","title":"4. Manual curation","text":"<p>Because automated gene predictions are not perfect, manual inspection and fixing is often required. The most commonly used software for this is Apollo/WebApollo.</p> <p>We will not curate any gene models as part of this practical, but you can learn about gene model curation through these YouTube videos:</p> <ol> <li>EMBL-ABR training 20171121 - Genome Annotation using Apollo</li> <li>The i5k Workspace@NAL: a pan-Arthropoda genome database</li> </ol>"},{"location":"practicals/pt-4-map-call/","title":"Part 4: Read Mapping and Variant Calling","text":""},{"location":"practicals/pt-4-map-call/#1-introduction","title":"1. Introduction","text":"<p>Different types of genetic variants exist. Commonly, people look at single nucleotide polymorphisms (SNPs, sometimes also known as single nucleotide variants, SNVs). Other classes include small insertions and deletions (known collectively as indels), as well as larger structural variants such as large insertions, deletions, inversions and translocations. Some of these larger ones are described as copy number variants, CNVs).</p> <p>Here, we aim to identify genetic variation and genotypes from short paired-end Illumina reads. First, we will map the reads from each individual to a reference assembly similar to the one created in the previous practical (you can use your assembly too, but that is better left as an exercise for later!). Then we will find the positions where at least some of the individuals differ from the reference genome sequence (and from each other).</p>"},{"location":"practicals/pt-4-map-call/#2-pipeline","title":"2. Pipeline","text":"<p>We will analyse subsets of whole-genome sequences of several fire ant individuals. The fire ant, Solenopsis invicta, is notable for having two colony types, with some colonies having one queen and other colonies having multiple queens. Previous work showed that this trait is associated with the B vs. b alleles of a genetic marker. In this practical, we aim to understand whether there are multiple genetic differences between B and b ants. As a reminder, all ants in single queen colonies carry the B allele of the genetic marker, while individuals carrying the b alelles exist exclusively in multiple queen colonies.</p> <p>We will use a subset of the reads from whole-genome sequencing of 14 male fire ants. </p> <ul> <li>Samples 1B to 7B are from single-queen colonies.</li> <li>Samples 1b to 7b are from multiple-queen colonies.</li> </ul> <p>Ants are haplodiploid, which means that females are diploid and males are haploid. Here we will use only males, so all our samples are haploid, which makes variant calling easier. </p> <p>The aim of this practical is to genotype these 14 individuals. We will:</p> <ol> <li>Align the reads of each individual to a reference genome assembly using the    aligner bowtie2.</li> <li>Find positions that differ between each individual and the reference with    the software samtools and bcftools.</li> <li>Filter the SNP calls to produce a set of good-quality SNPs.</li> <li>Visualise the alignments and the SNP calls in the genome browser IGV.</li> </ol>"},{"location":"practicals/pt-4-map-call/#3-setting-up","title":"3. Setting Up","text":"<p>Task</p> <p>Following the same procedure from the first read cleaning practical   Part 1: Read cleaning, create a new main directory for today's practical (e.g., <code>2025-09-29-mapping</code>), the <code>input</code>, <code>tmp</code>, and <code>results</code> subdirectories, and the file <code>WHATIDID.txt</code> to log your commands. </p> <p>To help get you started    <pre><code>mkdir 2025-09-29-mapping\n</code></pre></p> <p>Your directory hierarchy should look like the following</p> <p>Terminal</p> <pre><code>2025-09-29-mapping\n\u251c\u2500\u2500 input\n\u251c\u2500\u2500 tmp\n\u251c\u2500\u2500 results\n\u2514\u2500\u2500 WHATIDID.txt\n</code></pre> <p>Task</p> <p>Now create a symlink (using <code>ln -s</code>) from the reference genome <code>/shared/data/popgen/reference.fa</code> and the directory containing the reads <code>/shared/data/popgen/reads</code> to your <code>input</code> subdirectory:</p> <p>Note: Remember to keep a record of the commands you run in your <code>WHATIDID.txt</code> file.</p> <p>On Completion your directory hierarchy should look like the following</p> <p>Terminal</p> <pre><code>2025-09-29-mapping/\n\u251c\u2500\u2500 input\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 reads -&gt; /shared/data/popgen/reads\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 reference.fa -&gt; /shared/data/popgen/reference.fa\n\u251c\u2500\u2500 results\n\u251c\u2500\u2500 tmp\n\u2514\u2500\u2500 WHATIDID.txt\n</code></pre> <p>Task</p> <p>To check that the reference genome and the reads directory are linked   (not copied) in the <code>input</code> directory, you could use one of the following   commands from your <code>input</code> directory:</p> <pre><code>ls -al\n</code></pre> <p>Now check how many scaffolds there are in the reference genome:</p> <pre><code>grep \"^&gt;\" input/reference.fa\n</code></pre> <p>Question</p> <p>Have a look at the fastq files (<code>ls input/reads</code>).</p> <ul> <li>Why does each sample have two sets of reads?</li> <li>What is each line of the <code>.fq.gz</code> file? (you can use <code>zless</code>)</li> <li>How many reads do we have in individual f1_B? (you can use <code>zless</code> and <code>wc -l</code>)</li> <li>How long are the reads (are all their lengths equal)?</li> <li>Knowing that each scaffold is 200kb, calculate which coverage you would expect per base pair of individual f1_B?</li> </ul>"},{"location":"practicals/pt-4-map-call/#4-aligning-reads-to-a-reference-assembly","title":"4. Aligning reads to a reference assembly","text":"<p>The first step in our pipeline is to align the paired end reads to the reference genome. We are using the software bowtie2, which was created to align short read sequences to long sequences such as the scaffolds in a reference assembly. Like most aligners, bowtie2 works in two steps:</p> <ol> <li> <p>The scaffold sequence (sometimes known as the database) is indexed, in this case using the Burrows-Wheeler Transform. This manner of representing the genome enables it to be stored using less memory, and thus enables memory-efficient alignment of sequence reads to the reference.</p> </li> <li> <p>Only subsequently will we do the actual alignment of Illumina reads from individual samples to the indexed reference genome.</p> </li> </ol> <p>Task</p> <p>Let's start by linking scaffold sequences to our <code>tmp</code> directory.</p> <p>Symlink <code>reference.fa</code> to <code>tmp/</code>:</p> <pre><code>cd tmp\nln -s ~/2025-09-29-mapping/input/reference.fa .\ncd ..\n</code></pre> <p>Build the index (step 1):</p> <pre><code>bowtie2-build tmp/reference.fa tmp/reference\n</code></pre> <p>Perform the alignment (step 2):</p> <pre><code># Create a directory for the alignments.\nmkdir tmp/alignments\n\n# Use bowtie2 to align paired reads from f1_B sample to the reference.\nbowtie2 --local -x tmp/reference -1 input/reads/f1_B.1.fq.gz -2 input/reads/f1_B.2.fq.gz &gt; tmp/alignments/f1_B.sam\n</code></pre> <p>Question</p> <ul> <li>What is the meaning of the <code>-1</code> and <code>-2</code> parameters?</li> <li>Why do we use <code>--local</code> parameter?</li> </ul> <p>The command produced a SAM file (Sequence Alignment/Map file), which is a text representation of the standard format used to store sequence alignments. Have a quick look at the file using <code>less</code>. The file includes a header (lines starting with the <code>@</code> symbol), and a line for every read aligned to the reference assembly. For each read, we are given a mapping quality value, the position of both reads in a pair, the actual sequence and its quality by base pair, and a series of flags with additional measures of mapping quality.</p> <p>Question</p> <p>Can you tell, by looking at the SAM file specification linked above, which columns correspond to which information?</p> <p>We now need to run bowtie2 for all the other samples. We could do this by typing the same command another 13 times (changing the sample name). Alternatively, we can use GNU parallel, a tool that helps to automate running the same command on several samples.</p> <p>Task</p> <p>To use <code>parallel</code>, lets first create a file that contains all sample names:</p> <pre><code>ls input/reads/*fq.gz | cut -d '/' -f 3 | cut -d '.' -f 1 | sort | uniq &gt; tmp/names.txt\n</code></pre> <p>Lets break this command down to understand what is going on:</p> <ul> <li><code>ls input/reads/*fq.gz</code>: Lists the paths of all files in input/reads/ that end with fq.gz`</li> <li><code>cut -d '/' -f 3</code> : Split the path using <code>/</code> as the deliminator and take the 3rd element (aka just the file name).</li> <li><code>cut -d '.' -f 1</code> : Split the output using <code>.</code> as the deliminator and take 1st elemnt (sample name )</li> <li><code>sort</code> sort the resulting list alphabetically </li> <li><code>uniq</code> remove duplicate lines in the out (aka only 1 entry per sample).</li> </ul> <p>Then, run bowtie2 on each sample, this will take a few minutes:</p> <pre><code>cat tmp/names.txt | parallel --verbose --jobs 1 \"bowtie2 --local -x tmp/reference -1 input/reads/{}.1.fq.gz -2 input/reads/{}.2.fq.gz &gt; tmp/alignments/{}.sam\"\n</code></pre> <p>Because the SAM files include a lot of information, they tend to occupy a lot of space (even with our small example data). Therefore, SAM files are generally compressed into BAM files (Binary sAM). Most tools that use aligned reads require BAM files that have been sorted and indexed by genomic position. This is done using samtools, a set of tools created to manipulate SAM/BAM files.</p> <p>Task</p> <p>First, sort the SAM file by scaffold position and output in BAM format:</p> <pre><code>samtools sort -O BAM tmp/alignments/f1_B.sam &gt; tmp/alignments/f1_B.bam\n</code></pre> <p>Info</p> <p>You may get the warning below: </p> <p><pre><code>samtools: /usr/local/miniconda/bin/../lib/libtinfow.so.6: no version information available (required by samtools)\nsamtools: /usr/local/miniconda/bin/../lib/libncursesw.so.6: no version information available (required by samtools)\n</code></pre>   Please ignore this message as the command has still run successfully!</p> <p>Task</p> <p>Then, index the BAM file generated above (creates f1_B.bam.bai):</p> <pre><code>samtools index tmp/alignments/f1_B.bam\n</code></pre> <p>Also in this case, we can use <code>parallel</code> to run this step for all the samples:</p> <pre><code># For each sample, sort the SAM file for each and convert to BAM.\ncat tmp/names.txt | parallel --verbose \"samtools sort -O BAM tmp/alignments/{}.sam &gt; tmp/alignments/{}.bam\"\n\n# Index the BAM file for each sample.\ncat tmp/names.txt | parallel --verbose \"samtools index tmp/alignments/{}.bam\"\n</code></pre> <p>Now check that a <code>.bam</code> and a <code>.bai</code> file exists for each sample.</p> <p>To view what's in a BAM file, you have to use <code>samtools view</code>:</p> <pre><code># View the entire BAM file:\nsamtools view tmp/alignments/f1_B.bam | less -S\n\n# View a particular region of the reference:\nsamtools view tmp/alignments/f1_B.bam scaffold_1:10000-10500 | less -S\n</code></pre> <p>Copy the <code>.bam</code> and <code>.bai</code> files to the <code>results</code> directory.</p> <pre><code>cp tmp/alignments/*.bam results/\ncp tmp/alignments/*.bai results/\n</code></pre> <p>Once you are sure the files are in <code>results</code>, clean the <code>tmp</code> directory.</p> <pre><code>rm -ri tmp\n</code></pre>"},{"location":"practicals/pt-4-map-call/#5-variant-calling","title":"5. Variant calling","text":"<p>Task</p> <p>Create a new directory in your <code>home</code> for the second part of today's practical (e.g., <code>2025-09-29-genotyping</code>). You will want to set up the relevant subdirectories  and <code>WHATIDID.txt</code> file, as you have done before. Then symlink (<code>ln -s</code>) the reference genome <code>/shared/data/popgen/reference.fa</code> and the alignments from the mapping part of the practical (both <code>.bam</code> and <code>.bai</code> files) to your input` directory.</p> <p>To help get you started    <pre><code>mkdir 2025-09-29-genotyping\n</code></pre></p> <p>Your directory hierarchy should look like the following when running <code>tree</code></p> <p>Terminal</p> <pre><code>2025-09-29-genotyping/\n\u251c\u2500\u2500 input\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 -&gt; /shared/data/popgen/reference.fa\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 -&gt; ~/2025-09-29-mapping/results/f1_B.bam\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 -&gt; ~/2025-09-29-mapping/results/f1_B.bam.bai\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 -&gt; ...\n\u251c\u2500\u2500 results\n\u251c\u2500\u2500 tmp\n\u2514\u2500\u2500 WHATIDID.txt\n</code></pre> <p>Info</p> <p>Note: When you create links from one directory to another, it is better to use the absolute path for links like <code>~/2025-09-29-mapping/results/*.bam*</code> instead of <code>../../2025-09-29-mapping/results/*.bam</code></p> <p>Several variant calling approaches exist. The simplest approach is to look for positions where the mapped reads consistently have a different base than the reference assembly (this is called consensus approach). For this, we will use bcftools, a set of tools to call variants and manipulate them. We will run two commands:</p> <pre><code>bcftools mpileup\n</code></pre> <p>The previous command looks for inconsistencies between the reference and the aligned reads, followed by:</p> <pre><code>bcftools call\n</code></pre> <p>which interprets them as variants.</p> <p>We will use multiallelic caller (option <code>-m</code>) of <code>bcftools</code> and set all individuals as haploid.</p> <p>Task</p> <p>First link <code>reference.fa</code> to <code>tmp/</code></p> <pre><code>cd tmp\nln -s ~/2025-09-29-genotyping/input/reference.fa .\ncd ..\n</code></pre> <p>Then create the index of the reference (different from that used by bowtie2):</p> <pre><code>samtools faidx tmp/reference.fa\n</code></pre> <p>Finally, call the variants using bcftools: identify all differences between   reference and reads using <code>mpileup</code> subcommand and pipe it to call subcommand   to determine if the identified difference are variants.</p> <pre><code>bcftools mpileup --output-type u --fasta-ref tmp/reference.fa input/*.bam | bcftools call --ploidy 1 --variants-only --multiallelic-caller &gt; tmp/calls.vcf\n</code></pre> <p>The output <code>calls.vcf</code> is a file in the VCF (Variant Call Format) format, which contains the position, nature and quality of the called variants.</p> <p>Question</p> <ul> <li>Why we are using the <code>--variants-only</code> option in <code>bcftools call</code>?</li> <li>Is it ever useful to leave it out?</li> </ul> <p>Task</p> <p>Check that the output VCF file has the right extension <code>.vcf</code>:</p> <pre><code>ls tmp/calls*\n</code></pre> <p>If the listed file has a different name from the expected <code>calls.vcf</code>, rename it by running the command:</p> <pre><code>mv tmp/YOUR_CALLS_FILENAME tmp/calls.vcf\n</code></pre> <p>Where you need to substitute YOUR_CALLS_FILENAME with the filename you got from the <code>ls tmp/calls*</code> command.</p> <p>Now Let's look at the VCF file produced by typing <code>less -S tmp/calls.vcf</code>. The file is composed of a header and rows for all the variant positions.  Look at the different columns and check what each is (the header includes labels). Notice that some columns include several fields.</p> <p>Question</p> <ul> <li>Where does the header start and end?</li> <li>How is the genotype of each sample coded?</li> <li>How many variants were identified?</li> <li>Can you tell the difference between SNPs and indels? How many of each have been identified?</li> </ul>"},{"location":"practicals/pt-4-map-call/#6-quality-filtering-of-variant-calls","title":"6. Quality filtering of variant calls","text":"<p>Some potentially identified genetic variations may be unreliable - for example, due to sequencing errors or ambiguous mapping. The VCF file includes several fields with quality information that enable us to remove lower-confidence genetic variants. The most obvious is the column QUAL, which provides a Phred-scale quality score for each genetic variant.</p> <p>Question</p> <ul> <li>What does a Phred-scale quality score of 30 mean?</li> </ul> <p>We will filter the VCF using <code>bcftools filter</code>. Based on the distribution of quality values we see in the file, we suggest removing variants with a quality less than 30:</p> <p>Task</p> <p>Remove variant sites with a quality score under 30. Then remove sites that have a missing genotype call.   <pre><code>bcftools filter --exclude 'QUAL &lt; 30' tmp/calls.vcf | bcftools view --genotype ^miss &gt; tmp/filtered_calls.vcf\n</code></pre></p> <p>In real scenarios, it may be important to filter by other parameters, but we will also use a different variant calling &amp; genotyping approach. bcftools is not normally used for real projects.</p> <p>In the downstream analysis, we only want to look at sites that are:</p> <ol> <li>snps (--types snps)</li> <li>biallelic (--min-alleles 2 --max-alleles 2)</li> <li>where the minor allele is present in at least one individual (because we are    not interested in the sites where all individuals are different from the    reference, yet equal to each other)</li> </ol> <p>Task</p> <p>Now filter your data again based on this criteria by selecting biallelic variant sites that are SNPs and at least one individual differs from the rest:</p> <pre><code>bcftools view --types snps --min-alleles 2 --max-alleles 2 --min-ac 1:minor tmp/filtered_calls.vcf &gt; tmp/snp.vcf\n</code></pre> <p>(Always check that the output file in <code>tmp</code> has the right extension <code>.vcf</code>)</p> <p>Question</p> <ul> <li>How many SNPs does the resulting VCF file have?</li> <li>Can you find any other parameters indicating the quality of the site?</li> <li>Can you find any other parameters indicating the quality of the variant call for a given individual on a given site?</li> </ul> <p>In this practical, we only looked at a subset of the fire ant genome. When calling variants for the entire genome and using hundreds or thousands of samples, the resulting VCF files can be very large (reaching terabytes for cancer genomics projects!). It is thus a good idea to compress and index a VCF file. This is typically done using <code>bgzip</code> (for compression) and <code>tabix</code> (for indexing - tabix requires the file to be compressed using <code>bgzip</code>).</p> <p>Task</p> <p>Compress the VCF file using <code>bgzip</code>. This will remove the <code>snp.vcf</code> file and produce <code>snp.vcf.gz</code> file in its place:</p> <pre><code>bgzip tmp/snp.vcf\n</code></pre> <p>Index the compressed VCF file. This will produce a <code>.tbi</code> file alongside the <code>snp.vcf.gz</code> file.</p> <pre><code>tabix tmp/snp.vcf.gz\n</code></pre> <p>Now that we have a SNP set, we can copy it to <code>results</code> directory:</p> <pre><code>cp tmp/snp.vcf.gz results\ncp tmp/snp.vcf.gz.tbi results\n</code></pre>"},{"location":"practicals/pt-4-map-call/#7-viewing-the-results-using-igv-integrative-genome-viewer","title":"7. Viewing the results using IGV (Integrative Genome Viewer)","text":"<p>In this part of the practical, we will use the software IGV to visualise the alignments and the SNPs we generated, and verify some of the called SNPs.</p> <p>Task</p> <ol> <li>Copy the BAM and their index files (<code>.bai</code>) to <code>~/www/igv/data</code>.</li> <li>Copy the <code>snp.vcf.gz</code> and its index file (<code>.tbi</code>) to <code>~/www/igv/data</code>.</li> </ol> <p>To visualise them, open IGV by clicking on the IGV link in your personal module page (e.g., http://bob.genomicscourse.com).</p> <p></p> <p>Upon loading your webpage should look like below, with the option to zoom in to see feature! By scrolling down, you can see all the bam files are loaded and named on the left hand side, as circled in red. </p> <p></p> <p>If you scroll to the bottom of the web-page you will also see your VCF file!</p> <p>Now lets zoom in to begin to see our aligned reads. For each BAM file we see two plots, the top being the coverage at each position and the bottom highlighting the individual aligned reads which are shown in grey. </p> <p></p> <p>When you observe colour in the IGV plot, this typically indicates that there is a difference between the read sequence and the underlying refrence sequence. This could be due to the presence of a genetic variant or possibly due sequencing error!  To help you tell the difference please consider the plots below which highlight how SNPs, Insertions and Deletions are represented in IGV </p> <p>Note - these are from a different practical, however the colouration remains the same regarding how IGV highlights potential genetic variants.</p> <p></p> <p></p> <p></p> <p>Task</p> <ul> <li> <p>Using the search box at the top of the IGV webpage go to the follow position scaffold_2:95,983-96,079 and see what variants you can see in the f1_B.bam sample! (You should observe a SNP and Deletion)</p> </li> <li> <p>Using the search box at the top of the IGV webpage go to the follow position scaffold_2:97,597-97,636 and see what variants you can see in the f1_B.bam sample! (You should observe an Insertion)</p> </li> </ul> <p>Here, we use igv.js which is designed to be embedded in web pages and the installation is pre-configured to use the assembly (<code>reference.fa</code> file) you used for variant calling.</p> <p>Question</p> <ul> <li>Can you identify genetic variants and sequencing errors?</li> <li>Has bcftools/mpileup recovered the same genetic variants, idicated in by the snps.vcf.gz, as you would by looking at the alignments with IGV?</li> <li>Do you think our filtering was effective?</li> </ul>"},{"location":"practicals/pt-5-popgen/","title":"Part 5 - Population genetics in R","text":""},{"location":"practicals/pt-5-popgen/#1-introduction","title":"1. Introduction","text":"<p>In this practical, we will use samples with two genotypes associated to two  distinct phenotypes. Also, our example assembly consists of two scaffolds,  from two different chromosomes:</p> Genotype label Phenotype description B single-queen colony b multiple-queen colony <p>The aim of our analysis is to test whether any parts of this assembly differ  between the individuals from these two groups (B and b).</p> <p>In the first part of the analysis, we are going to create a heat map of the  genotypes of the individuals and we are going to run Principal Component  Analysis (PCA) on these genotypes. This will allow us to test if any of the  individuals cluster together by their B/b genotype. This will be done using  the adegenet package in R.</p> <p>In the second part, we are going to estimate the genetic differentiation between the two groups (B and b). We will do this analysis over a sliding window, to see if the differentiation between B and b are specific to any portion of the genome. We will also measure the genetic diversity among each of the groups, which may tell us something about the evolutionary history of the portions of genome represented in our assembly. This will be done using the PopGenome  package in R.</p> <p>Info</p> <p>If you are unfamiliar with R do not worry! This practical is not to assess your programming skills, all you need to do is copy and paste the relevant commands! What we are interested in is your ability to interpret the outcome of each analysis and to understand fundamentally what is going on! </p>"},{"location":"practicals/pt-5-popgen/#2-input-into-r","title":"2. Input into R","text":"<p>Task</p> <p>As before, create a directory for this practical (e.g., <code>2025-09-30-population_genetics</code>). Copy over the R markdown notebook <code>/shared/data/popgen/popgen.Rmd</code> to your project directory. Create <code>input/</code>  subdirectory and symlink the <code>snp.vcf.gz</code> and <code>snp.vcf.gz.tbi</code> file we created in the last practical to it. </p> <p>If you don't have these files, you can use the ones in: <code>/shared/data/backup_vcf</code>.  </p> <p>Once set up, the output of the <code>tree</code> command should look like this:</p> <p>Terminal</p> <pre><code>2025-09-30-population_genetics\n\u251c\u2500\u2500 input\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 snp.vcf.gz -&gt; /home/alice/2025-09-29-genotyping/results/snp.vcf.gz\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 snp.vcf.gz.tbi -&gt; /home/alice/2025-09-29-genotyping/results/snp.vcf.gz.tbi\n\u251c\u2500\u2500 tmp\n\u251c\u2500\u2500 results\n\u2514\u2500\u2500 WHATIDID.txt\n\u2514\u2500\u2500 popgen.Rmd\n</code></pre> <p>Task</p> <p>Next, open RStudio by clicking on the 'RStudio' link in your personal module page (e.g., bt007.genomicscourse.com). Login using your username (e.g., bt007) and the password that you use for ssh.</p> <p></p> <p>Task</p> <p>In RStudio, open the file <code>popgen.Rmd</code> (as highlighted in red in the image below) and work through the rest of the practical there.</p> <p></p> <p>Once opened, make sure to click the visual button in the top left hand corner (as highlighted in red in the image below). </p> <p></p> <p>You can now work through this file to complete the practical. When you encouter a command box, please select the green play button on the right hand side, as highlighted in red in the image below, to run the necessary commands! </p> <p></p>"}]}